{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation, Reshape\n",
    "from keras.layers.convolutional import Conv2D, ZeroPadding2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "import tempfile\n",
    "from keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            feature\n",
       "0      0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1      0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2      2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3      4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4      6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel=train_data['feature'].values\n",
    "label=train_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70 80 82 72 58 58 60 63 54 58 60 48 89 115 121 119 115 110 98 91 84 84 90 99 110 126 143 153 158 171 169 172 169 165 129 110 113 107 95 79 66 62 56 57 61 52 43 41 65 61 58 57 56 69 75 70 65 56 54 105 146 154 151 151 155 155 150 147 147 148 152 158 164 172 177 182 186 189 188 190 188 180 167 116 95 103 97 77 72 62 55 58 54 56 52 44 50 43 54 64 63 71 68 64 52 66 119 156 161 164 163 164 167 168 170 174 175 176 178 179 183 187 190 195 197 198 197 198 195 191 190 145 86 100 90 65 57 60 54 51 41 49 56 47 38 44 63 55 46 52 54 55 83 138 157 158 165 168 172 171 173 176 179 179 180 182 185 187 189 189 192 197 200 199 196 198 200 198 197 177 91 87 96 58 58 59 51 42 37 41 47 45 37 35 36 30 41 47 59 94 141 159 161 161 164 170 171 172 176 178 179 182 183 183 187 189 192 192 194 195 200 200 199 199 200 201 197 193 111 71 108 69 55 61 51 42 43 56 54 44 24 29 31 45 61 72 100 136 150 159 163 162 163 170 172 171 174 177 177 180 187 186 187 189 192 192 194 195 196 197 199 200 201 200 197 201 137 58 98 92 57 62 53 47 41 40 51 43 24 35 52 63 75 104 129 143 149 158 162 164 166 171 173 172 174 178 178 179 187 188 188 191 193 194 195 198 199 199 197 198 197 197 197 201 164 52 78 87 69 58 56 50 54 39 44 42 26 31 49 65 91 119 134 145 147 152 159 163 167 171 170 169 174 178 178 179 187 187 185 187 190 188 187 191 197 201 199 199 200 197 196 197 182 58 62 77 61 60 55 49 59 52 54 44 22 30 47 68 102 123 136 144 148 150 153 157 167 172 173 170 171 177 179 178 186 190 186 189 196 193 191 194 190 190 192 197 201 203 199 194 189 69 48 74 56 60 57 50 59 59 51 41 20 34 47 79 111 132 139 143 145 147 150 151 160 169 172 171 167 171 177 177 174 180 182 181 192 196 189 192 198 195 194 196 198 201 202 195 189 70 39 69 61 61 61 53 59 59 45 40 26 40 61 93 124 135 138 142 144 146 151 152 158 165 168 168 165 161 164 173 172 167 172 167 180 198 198 193 199 195 194 198 200 198 197 195 190 65 35 68 59 59 62 57 60 59 50 44 32 54 90 115 132 137 138 140 144 146 146 156 165 168 174 176 176 175 168 168 169 171 175 171 172 192 194 184 198 205 201 194 195 193 195 192 186 57 38 72 65 57 62 58 57 60 54 49 47 79 116 130 138 141 141 139 141 143 145 157 164 164 166 173 174 176 179 179 176 181 189 188 173 180 175 160 182 189 198 192 189 190 190 188 172 46 44 64 66 59 62 57 56 62 53 50 66 103 133 137 141 143 141 136 132 131 136 127 118 111 107 108 123 131 143 154 158 166 177 181 175 170 159 148 171 161 176 185 192 194 188 190 162 53 49 58 63 61 61 55 56 61 51 50 81 116 139 142 142 146 144 136 128 119 112 97 85 90 91 88 92 90 80 81 84 106 122 132 144 145 144 147 163 147 163 173 181 190 187 191 167 61 48 53 61 61 58 54 56 61 51 53 89 123 140 144 145 146 147 136 122 107 99 95 92 90 87 83 76 67 52 46 52 63 69 83 96 119 132 148 159 136 137 143 138 143 152 156 156 70 48 50 59 61 57 54 54 61 52 56 93 124 135 140 144 148 150 140 125 114 101 80 54 56 54 41 41 33 40 39 35 49 60 63 74 107 129 147 147 116 111 100 77 76 86 108 111 73 49 50 60 62 60 57 55 63 59 56 89 121 134 139 146 151 152 150 141 127 111 96 77 85 70 32 31 37 91 65 50 48 59 73 83 112 136 155 130 60 46 38 40 43 81 116 91 72 52 48 58 62 62 59 53 61 59 52 85 114 134 140 147 154 159 158 153 145 143 150 126 121 125 68 45 89 137 95 70 78 75 95 109 131 153 171 94 23 16 32 82 82 65 113 77 71 54 48 56 62 62 60 53 60 56 52 75 108 133 141 149 158 166 169 167 163 156 155 146 112 119 134 127 142 140 121 117 129 114 120 129 146 174 191 98 46 33 33 109 147 98 109 67 73 55 50 56 64 64 61 58 61 53 54 64 106 129 140 148 159 169 175 176 174 165 159 156 145 120 115 124 127 131 133 141 147 142 141 147 161 182 202 154 114 96 100 158 158 153 123 61 76 57 48 56 64 64 63 62 61 54 55 44 97 131 137 147 158 168 177 181 183 179 170 168 169 165 155 152 151 152 154 162 165 158 153 158 168 187 206 186 147 135 144 145 152 178 115 57 74 58 48 58 64 63 63 59 63 55 53 66 104 130 132 144 153 162 170 180 185 187 181 178 182 180 177 173 171 171 177 176 172 164 161 167 164 185 207 197 173 152 141 141 161 191 104 54 69 60 48 57 65 62 60 57 64 55 50 94 111 124 130 135 150 159 163 172 179 184 184 178 178 177 173 171 174 177 178 176 169 165 161 163 161 180 205 201 183 171 177 178 180 194 101 55 65 60 47 55 65 63 59 58 63 57 52 90 105 117 122 130 143 153 157 163 171 174 182 183 182 178 174 175 175 177 175 172 163 161 159 157 162 178 200 201 188 181 172 177 187 198 98 57 63 61 48 52 61 64 63 60 65 57 51 95 104 113 117 127 136 145 152 156 162 162 165 173 177 182 183 183 180 181 177 165 153 154 152 153 160 174 193 200 188 185 180 182 192 196 101 60 60 56 49 50 60 66 64 62 64 59 53 99 104 111 112 118 132 142 147 155 158 160 159 162 171 176 184 186 183 180 169 154 141 135 145 155 164 180 196 205 188 189 188 189 193 192 98 61 64 55 49 49 60 66 63 64 63 60 57 99 105 108 112 113 125 139 143 150 155 158 164 169 174 176 182 183 182 177 163 141 133 147 151 164 170 185 200 210 194 188 192 186 185 180 88 64 67 60 46 50 59 65 64 64 64 59 56 101 103 108 109 109 118 134 143 143 147 155 159 166 171 174 177 179 178 172 153 129 143 161 159 166 171 186 197 207 203 185 191 183 179 164 73 67 67 66 48 50 57 65 65 63 64 61 57 103 108 114 112 110 115 128 138 144 145 152 156 159 164 168 172 172 169 161 139 125 147 156 161 162 164 180 188 188 197 185 187 181 180 137 65 70 68 70 52 47 53 62 65 63 65 61 58 105 109 112 120 113 112 122 134 141 149 150 153 155 159 164 167 167 162 152 134 115 126 119 106 99 109 141 158 150 155 175 184 176 175 106 63 70 68 68 50 46 50 57 63 63 64 61 59 107 110 110 117 117 114 117 128 137 147 148 150 153 156 161 162 163 156 150 148 105 70 45 26 25 47 73 74 79 128 177 180 173 157 77 66 68 67 68 52 49 51 56 62 62 62 62 60 101 107 108 114 115 114 117 125 134 143 148 149 152 154 158 160 158 155 160 158 132 88 73 73 64 52 66 91 138 160 174 173 171 125 64 67 63 64 68 54 50 49 54 60 60 60 62 60 98 105 105 109 111 114 117 125 131 139 145 148 153 153 156 157 156 161 168 165 153 139 122 115 105 89 103 150 182 161 171 173 162 89 64 64 62 64 69 56 48 49 56 58 60 59 62 60 89 99 108 106 109 111 119 120 125 134 140 146 152 153 153 153 156 159 162 160 150 136 129 133 133 122 133 148 178 168 168 175 132 61 67 66 65 63 69 57 47 50 55 58 59 61 62 60 89 96 105 107 105 107 117 120 123 124 133 141 149 153 151 145 151 145 139 140 138 128 126 124 129 125 136 142 164 172 168 168 87 58 67 63 62 61 69 57 39 44 55 56 59 63 62 62 84 91 92 98 102 103 113 119 121 118 128 138 146 151 147 142 140 128 127 128 129 126 135 140 135 130 143 146 149 166 174 131 62 65 62 59 67 63 68 83 89 65 42 52 60 60 62 63 77 84 84 91 99 101 107 112 117 118 122 134 145 149 144 134 127 127 129 130 134 125 126 132 152 153 151 150 151 165 171 87 59 65 64 61 58 86 122 138 208 207 154 71 52 56 55 56 69 77 83 85 93 91 102 112 116 118 119 127 140 144 142 131 112 95 85 75 62 58 56 59 87 88 83 127 142 165 149 62 65 62 59 77 113 192 156 84 185 196 197 168 81 70 75 69 58 65 73 82 81 79 95 107 114 116 116 123 136 142 136 132 131 102 71 58 49 41 33 41 36 49 60 99 136 168 111 53 63 71 138 186 203 195 146 87 91 72 79 95 103 82 61 74 55 57 68 75 76 77 84 96 106 110 111 121 130 138 136 142 153 159 152 152 154 145 133 136 147 158 156 155 147 158 74 57 60 123 181 174 126 89 72 67 57 43 55 67 76 86 60 45 51 45 52 68 75 73 77 88 96 100 104 113 115 121 134 146 149 146 149 148 155 168 174 179 178 169 169 174 161 131 44 47 82 150 168 136 104 75 66 80 67 58 48 54 68 88 121 102 51 45 38 53 66 65 70 86 92 96 102 103 109 116 130 136 136 133 136 138 137 135 128 130 143 158 165 164 147 87 62 74 123 160 170 100 99 107 79 71 86 75 57 45 49 65 122 130 43 48 40 39 55 61 59 71 82 87 88 93 105 118 123 128 130 124 111 98 94 88 67 55 84 129 147 148 105 48 82 142 161 164 164 76 72 85 100 88 72 90 84 54 48 54 73 100 73 36 44 31 37 53 51 55 67 74 77 87 97 108 118 125 132 122 106 86 80 82 75 73 83 110 129 126 46 22 130 177 196 193 166 72 52 54 73 100 92 75 99 95 65 68 61 63 91 65 42 37 22 28 39 44 57 68 74 83 92 101 119 131 143 141 134 136 140 139 134 136 139 138 136 85 23 114 202 198 199 180 173 98 36 86 130 150 137 99 77 101 99 72 56 43 77 82 79 70 56 28 20 25 36 50 63 73 83 98 111 124 139 156 160 159 169 168 165 163 159 149 114 43 26 133 183 192 177 152 137 130 125 139 173 195 186 137 101 88 101 105 70 46 77 72 84 87 87 81 64 37 20 31 40 46 65 88 108 110 125 149 157 153 162 164 158 159 154 140 78 21 11 61 144 168 173 157 138 150 148 132 159 182 183 136 106 116 95 106 109 82'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixels=[ np.fromstring(x, dtype=float, sep=' ') for x in pixel ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  70.,   80.,   82., ...,  106.,  109.,   82.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixels=np.array(pixels)\n",
    "pixels=pixels.reshape(pixels.shape[0],48,48,1)\n",
    "pixels=pixels.astype('float32')\n",
    "pixels=pixels/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将类向量转换为二进制类矩阵\n",
    "label = np_utils.to_categorical(label, 7)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#分成训练集和测试集\n",
    "id=int(pixels.shape[0]*0.8)\n",
    "X_train=pixels[:id]\n",
    "X_test=pixels[id:]\n",
    "y_train=label[:id]\n",
    "y_test=label[id:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22967, 48, 48, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5742, 48, 48, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22967, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 41, 41, 32)        2080      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 41, 41, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 689)               794417    \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 689)               0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 689)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 7)                 4830      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 801,327\n",
      "Trainable params: 801,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义超参数\n",
    "n_filter=32\n",
    "batch_size = 256\n",
    "nb_classes = 7  # 分类树\n",
    "nb_epoch = 120  # 训练轮数\n",
    "\n",
    "img_rows, img_cols = 48, 48  # 图片维数\n",
    "kernel_size = (8, 8)  # 卷积核大小\n",
    "pool_size = (6, 6)  # 最大池化，池化核大小\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(n_filter,kernel_size,strides=1,input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())  # Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡\n",
    "model.add(Dense(689))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 模型编译\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.8210 - acc: 0.2464 - val_loss: 1.7758 - val_acc: 0.2680\n",
      "Epoch 2/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.7486 - acc: 0.3005 - val_loss: 1.6713 - val_acc: 0.3870\n",
      "Epoch 3/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.6808 - acc: 0.3354 - val_loss: 1.6424 - val_acc: 0.3899\n",
      "Epoch 4/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.6428 - acc: 0.3607 - val_loss: 1.5741 - val_acc: 0.4103\n",
      "Epoch 5/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.6191 - acc: 0.3744 - val_loss: 1.5591 - val_acc: 0.4093\n",
      "Epoch 6/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.6018 - acc: 0.3792 - val_loss: 1.5379 - val_acc: 0.4026\n",
      "Epoch 7/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.5862 - acc: 0.3849 - val_loss: 1.5209 - val_acc: 0.4270\n",
      "Epoch 8/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.5674 - acc: 0.3948 - val_loss: 1.5072 - val_acc: 0.4363\n",
      "Epoch 9/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.5561 - acc: 0.3997 - val_loss: 1.4974 - val_acc: 0.4363\n",
      "Epoch 10/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.5412 - acc: 0.4076 - val_loss: 1.4973 - val_acc: 0.4215\n",
      "Epoch 11/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.5306 - acc: 0.4111 - val_loss: 1.4768 - val_acc: 0.4324\n",
      "Epoch 12/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.5237 - acc: 0.4146 - val_loss: 1.4711 - val_acc: 0.4371\n",
      "Epoch 13/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.5142 - acc: 0.4161 - val_loss: 1.4545 - val_acc: 0.4441\n",
      "Epoch 14/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4983 - acc: 0.4251 - val_loss: 1.4405 - val_acc: 0.4509\n",
      "Epoch 15/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4953 - acc: 0.4265 - val_loss: 1.4330 - val_acc: 0.4584\n",
      "Epoch 16/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4857 - acc: 0.4304 - val_loss: 1.4283 - val_acc: 0.4592\n",
      "Epoch 17/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4766 - acc: 0.4317 - val_loss: 1.4181 - val_acc: 0.4678\n",
      "Epoch 18/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.4697 - acc: 0.4399 - val_loss: 1.4183 - val_acc: 0.4660\n",
      "Epoch 19/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.4625 - acc: 0.4370 - val_loss: 1.4274 - val_acc: 0.4549\n",
      "Epoch 20/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4581 - acc: 0.4417 - val_loss: 1.4160 - val_acc: 0.4643\n",
      "Epoch 21/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.4480 - acc: 0.4425 - val_loss: 1.4001 - val_acc: 0.4786\n",
      "Epoch 22/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.4430 - acc: 0.4466 - val_loss: 1.4207 - val_acc: 0.4486\n",
      "Epoch 23/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4356 - acc: 0.4424 - val_loss: 1.3882 - val_acc: 0.4805\n",
      "Epoch 24/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.4289 - acc: 0.4525 - val_loss: 1.3826 - val_acc: 0.4730\n",
      "Epoch 25/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4241 - acc: 0.4541 - val_loss: 1.3731 - val_acc: 0.4801\n",
      "Epoch 26/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4204 - acc: 0.4570 - val_loss: 1.3833 - val_acc: 0.4793\n",
      "Epoch 27/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.4131 - acc: 0.4595 - val_loss: 1.3847 - val_acc: 0.4892\n",
      "Epoch 28/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.4100 - acc: 0.4594 - val_loss: 1.3686 - val_acc: 0.4892\n",
      "Epoch 29/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.4032 - acc: 0.4609 - val_loss: 1.3550 - val_acc: 0.4909\n",
      "Epoch 30/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3993 - acc: 0.4658 - val_loss: 1.3645 - val_acc: 0.4843\n",
      "Epoch 31/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3928 - acc: 0.4673 - val_loss: 1.3538 - val_acc: 0.4930\n",
      "Epoch 32/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3862 - acc: 0.4715 - val_loss: 1.3736 - val_acc: 0.4929\n",
      "Epoch 33/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3817 - acc: 0.4719 - val_loss: 1.3459 - val_acc: 0.4927\n",
      "Epoch 34/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3802 - acc: 0.4701 - val_loss: 1.3561 - val_acc: 0.4909\n",
      "Epoch 35/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3699 - acc: 0.4768 - val_loss: 1.3400 - val_acc: 0.4904\n",
      "Epoch 36/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3666 - acc: 0.4784 - val_loss: 1.3507 - val_acc: 0.4871\n",
      "Epoch 37/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3591 - acc: 0.4798 - val_loss: 1.3454 - val_acc: 0.4962\n",
      "Epoch 38/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3571 - acc: 0.4834 - val_loss: 1.3354 - val_acc: 0.5098\n",
      "Epoch 39/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.3483 - acc: 0.4869 - val_loss: 1.3306 - val_acc: 0.4995\n",
      "Epoch 40/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.3483 - acc: 0.4845 - val_loss: 1.3279 - val_acc: 0.5054\n",
      "Epoch 41/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.3458 - acc: 0.4894 - val_loss: 1.3179 - val_acc: 0.5080\n",
      "Epoch 42/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.3390 - acc: 0.4891 - val_loss: 1.3371 - val_acc: 0.5103\n",
      "Epoch 43/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3329 - acc: 0.4907 - val_loss: 1.3136 - val_acc: 0.5162\n",
      "Epoch 44/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3299 - acc: 0.4942 - val_loss: 1.3361 - val_acc: 0.5047\n",
      "Epoch 45/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3246 - acc: 0.4965 - val_loss: 1.3076 - val_acc: 0.5098\n",
      "Epoch 46/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.3207 - acc: 0.4980 - val_loss: 1.3028 - val_acc: 0.5162\n",
      "Epoch 47/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3163 - acc: 0.4978 - val_loss: 1.3017 - val_acc: 0.5164\n",
      "Epoch 48/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3065 - acc: 0.5033 - val_loss: 1.3110 - val_acc: 0.5172\n",
      "Epoch 49/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.3059 - acc: 0.5053 - val_loss: 1.3098 - val_acc: 0.5169\n",
      "Epoch 50/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.3095 - acc: 0.5055 - val_loss: 1.2992 - val_acc: 0.5188\n",
      "Epoch 51/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2973 - acc: 0.5080 - val_loss: 1.2926 - val_acc: 0.5165\n",
      "Epoch 52/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2910 - acc: 0.5125 - val_loss: 1.2865 - val_acc: 0.5219\n",
      "Epoch 53/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2845 - acc: 0.5129 - val_loss: 1.2981 - val_acc: 0.5249\n",
      "Epoch 54/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2781 - acc: 0.5177 - val_loss: 1.2827 - val_acc: 0.5254\n",
      "Epoch 55/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2819 - acc: 0.5130 - val_loss: 1.2931 - val_acc: 0.5131\n",
      "Epoch 56/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2775 - acc: 0.5125 - val_loss: 1.2921 - val_acc: 0.5153\n",
      "Epoch 57/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2718 - acc: 0.5225 - val_loss: 1.2844 - val_acc: 0.5286\n",
      "Epoch 58/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2701 - acc: 0.5184 - val_loss: 1.2809 - val_acc: 0.5216\n",
      "Epoch 59/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2606 - acc: 0.5264 - val_loss: 1.2802 - val_acc: 0.5301\n",
      "Epoch 60/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2586 - acc: 0.5238 - val_loss: 1.2721 - val_acc: 0.5312\n",
      "Epoch 61/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2603 - acc: 0.5244 - val_loss: 1.2771 - val_acc: 0.5296\n",
      "Epoch 62/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2543 - acc: 0.5259 - val_loss: 1.2677 - val_acc: 0.5305\n",
      "Epoch 63/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2506 - acc: 0.5247 - val_loss: 1.2670 - val_acc: 0.5313\n",
      "Epoch 64/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2449 - acc: 0.5326 - val_loss: 1.2728 - val_acc: 0.5280\n",
      "Epoch 65/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2353 - acc: 0.5348 - val_loss: 1.2676 - val_acc: 0.5312\n",
      "Epoch 66/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2374 - acc: 0.5346 - val_loss: 1.2731 - val_acc: 0.5286\n",
      "Epoch 67/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2318 - acc: 0.5408 - val_loss: 1.2644 - val_acc: 0.5298\n",
      "Epoch 68/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2294 - acc: 0.5400 - val_loss: 1.2660 - val_acc: 0.5303\n",
      "Epoch 69/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2246 - acc: 0.5424 - val_loss: 1.2652 - val_acc: 0.5263\n",
      "Epoch 70/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2201 - acc: 0.5406 - val_loss: 1.2576 - val_acc: 0.5381\n",
      "Epoch 71/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2189 - acc: 0.5406 - val_loss: 1.2595 - val_acc: 0.5350\n",
      "Epoch 72/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2140 - acc: 0.5447 - val_loss: 1.2535 - val_acc: 0.5385\n",
      "Epoch 73/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.2138 - acc: 0.5464 - val_loss: 1.2553 - val_acc: 0.5366\n",
      "Epoch 74/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2069 - acc: 0.5448 - val_loss: 1.2499 - val_acc: 0.5373\n",
      "Epoch 75/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1955 - acc: 0.5488 - val_loss: 1.2671 - val_acc: 0.5294\n",
      "Epoch 76/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.2009 - acc: 0.5490 - val_loss: 1.2500 - val_acc: 0.5430\n",
      "Epoch 77/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1911 - acc: 0.5533 - val_loss: 1.2481 - val_acc: 0.5395\n",
      "Epoch 78/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1876 - acc: 0.5560 - val_loss: 1.2526 - val_acc: 0.5381\n",
      "Epoch 79/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1826 - acc: 0.5577 - val_loss: 1.2545 - val_acc: 0.5336\n",
      "Epoch 80/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1766 - acc: 0.5585 - val_loss: 1.2379 - val_acc: 0.5404\n",
      "Epoch 81/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1789 - acc: 0.5577 - val_loss: 1.2453 - val_acc: 0.5387\n",
      "Epoch 82/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1802 - acc: 0.5579 - val_loss: 1.2414 - val_acc: 0.5421\n",
      "Epoch 83/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.1692 - acc: 0.5634 - val_loss: 1.2379 - val_acc: 0.5448\n",
      "Epoch 84/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.1739 - acc: 0.5603 - val_loss: 1.2397 - val_acc: 0.5413\n",
      "Epoch 85/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1683 - acc: 0.5628 - val_loss: 1.2375 - val_acc: 0.5463\n",
      "Epoch 86/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1590 - acc: 0.5654 - val_loss: 1.2373 - val_acc: 0.5428\n",
      "Epoch 87/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1556 - acc: 0.5663 - val_loss: 1.2354 - val_acc: 0.5522\n",
      "Epoch 88/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1553 - acc: 0.5669 - val_loss: 1.2587 - val_acc: 0.5388\n",
      "Epoch 89/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.1515 - acc: 0.5707 - val_loss: 1.2337 - val_acc: 0.5418\n",
      "Epoch 90/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1516 - acc: 0.5686 - val_loss: 1.2385 - val_acc: 0.5423\n",
      "Epoch 91/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1447 - acc: 0.5750 - val_loss: 1.2340 - val_acc: 0.5425\n",
      "Epoch 92/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1458 - acc: 0.5761 - val_loss: 1.2346 - val_acc: 0.5481\n",
      "Epoch 93/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1328 - acc: 0.5780 - val_loss: 1.2404 - val_acc: 0.5416\n",
      "Epoch 94/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1335 - acc: 0.5785 - val_loss: 1.2268 - val_acc: 0.5467\n",
      "Epoch 95/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.1331 - acc: 0.5769 - val_loss: 1.2260 - val_acc: 0.5475\n",
      "Epoch 96/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1347 - acc: 0.5766 - val_loss: 1.2348 - val_acc: 0.5496\n",
      "Epoch 97/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1192 - acc: 0.5847 - val_loss: 1.2242 - val_acc: 0.5496\n",
      "Epoch 98/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.1199 - acc: 0.5809 - val_loss: 1.2220 - val_acc: 0.5486\n",
      "Epoch 99/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1126 - acc: 0.5848 - val_loss: 1.2244 - val_acc: 0.5517\n",
      "Epoch 100/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1163 - acc: 0.5874 - val_loss: 1.2246 - val_acc: 0.5505\n",
      "Epoch 101/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1114 - acc: 0.5870 - val_loss: 1.2253 - val_acc: 0.5510\n",
      "Epoch 102/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.1093 - acc: 0.5880 - val_loss: 1.2191 - val_acc: 0.5505\n",
      "Epoch 103/120\n",
      "22967/22967 [==============================] - 2s - loss: 1.1042 - acc: 0.5899 - val_loss: 1.2187 - val_acc: 0.5489\n",
      "Epoch 104/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.1023 - acc: 0.5856 - val_loss: 1.2248 - val_acc: 0.5488\n",
      "Epoch 105/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0991 - acc: 0.5904 - val_loss: 1.2184 - val_acc: 0.5514\n",
      "Epoch 106/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0974 - acc: 0.5899 - val_loss: 1.2172 - val_acc: 0.5503\n",
      "Epoch 107/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0910 - acc: 0.5936 - val_loss: 1.2257 - val_acc: 0.5482\n",
      "Epoch 108/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0776 - acc: 0.6022 - val_loss: 1.2184 - val_acc: 0.5540\n",
      "Epoch 109/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0861 - acc: 0.6006 - val_loss: 1.2236 - val_acc: 0.5522\n",
      "Epoch 110/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0823 - acc: 0.6028 - val_loss: 1.2185 - val_acc: 0.5552\n",
      "Epoch 111/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0798 - acc: 0.5961 - val_loss: 1.2191 - val_acc: 0.5540\n",
      "Epoch 112/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0753 - acc: 0.6030 - val_loss: 1.2222 - val_acc: 0.5526\n",
      "Epoch 113/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0716 - acc: 0.6046 - val_loss: 1.2138 - val_acc: 0.5526\n",
      "Epoch 114/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0681 - acc: 0.6071 - val_loss: 1.2173 - val_acc: 0.5522\n",
      "Epoch 115/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0707 - acc: 0.6046 - val_loss: 1.2094 - val_acc: 0.5552\n",
      "Epoch 116/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0676 - acc: 0.6037 - val_loss: 1.2128 - val_acc: 0.5526\n",
      "Epoch 117/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0610 - acc: 0.6076 - val_loss: 1.2141 - val_acc: 0.5533\n",
      "Epoch 118/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0560 - acc: 0.6034 - val_loss: 1.2104 - val_acc: 0.5547\n",
      "Epoch 119/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0625 - acc: 0.6081 - val_loss: 1.2180 - val_acc: 0.5569\n",
      "Epoch 120/120\n",
      "22967/22967 [==============================] - 1s - loss: 1.0533 - acc: 0.6100 - val_loss: 1.2102 - val_acc: 0.5515\n",
      "22752/22967 [============================>.] - ETA: 0s\n",
      "Train score: 0.829568496899\n",
      "Train accuracy: 0.764705882405\n",
      "5568/5742 [============================>.] - ETA: 0s\n",
      "Test score: 1.21016781789\n",
      "Test accuracy: 0.551549982584\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,validation_data=(X_test, y_test))\n",
    "\n",
    "# 模型评估或模型预测\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print('\\nTrain score:', score[0])  # 损失值  Test score: \n",
    "print('Train accuracy:', score[1])  # 准确率  Test accuracy: \n",
    "score = model.evaluate(X_test, y_test,)\n",
    "print('\\nTest score:', score[0])  # 损失值  Test score: \n",
    "print('Test accuracy:', score[1])  # 准确率  Test accuracy: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "_, fname = tempfile.mkstemp('.h5', dir='.')\n",
    "save_model(model, fname)\n",
    "new_model = load_model(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='tmpws60mjj1.h5'\n",
    "new_model = load_model(fname)\n",
    "# 画模型图\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(new_model,show_shapes=True,to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用训练好的模型预测未知图片的情感\n",
    "test_data=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            feature\n",
       "0   0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...\n",
       "1   1  156 184 198 202 204 207 210 212 213 214 215 21...\n",
       "2   2  69 118 61 60 96 121 103 87 103 88 70 90 115 12...\n",
       "3   3  205 203 236 157 83 158 120 116 94 86 155 180 2...\n",
       "4   4  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id=test_data['id'].values\n",
    "test_pixel=test_data['feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixels=[ np.fromstring(x, dtype=float, sep=' ') for x in test_pixel ]\n",
    "test_pixels=np.array(test_pixels)\n",
    "test_pixels=test_pixels.reshape(test_pixels.shape[0],48,48,1)\n",
    "test_pixels=test_pixels.astype('float32')\n",
    "test_pixels=test_pixels/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 48, 48, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=new_model.predict(test_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26876205,  0.01692498,  0.13947614,  0.03221936,  0.27480349,\n",
       "        0.01865733,  0.24915668], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[2][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(x):\n",
    "    count=0\n",
    "    maxnum=0\n",
    "    maxcount=0\n",
    "    for i in x:\n",
    "        if maxnum<i:\n",
    "            maxcount=count\n",
    "            maxnum=i\n",
    "        count=count+1\n",
    "    return maxcount\n",
    "y_label=[find(x) for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label=np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": test_id, \"label\": y_label}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
