{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''This script loads pre-trained word embeddings (GloVe embeddings)\n",
    "into a frozen Keras Embedding layer, and uses it to\n",
    "train a text classification model on the 20 Newsgroup dataset\n",
    "(classification of newsgroup messages into 20 different categories).\n",
    "GloVe embedding data can be found at:\n",
    "http://nlp.stanford.edu/data/glove.6B.zip\n",
    "(source page: http://nlp.stanford.edu/projects/glove/)\n",
    "20 Newsgroup data can be found at:\n",
    "http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
    "TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26688001,  0.39631999,  0.61690003, -0.77451003, -0.1039    ,\n",
       "        0.26697001,  0.27880001,  0.30992001,  0.0054685 , -0.085256  ,\n",
       "        0.73602003, -0.098432  ,  0.54790002, -0.030305  ,  0.33478999,\n",
       "        0.14094   , -0.0070003 ,  0.32569   ,  0.22902   ,  0.46557   ,\n",
       "       -0.19531   ,  0.37491   , -0.71390003, -0.51775002,  0.77038997,\n",
       "        1.08809996, -0.66011   , -0.16234   ,  0.91189998,  0.21046001,\n",
       "        0.047494  ,  1.00189996,  1.11329997,  0.70094001, -0.08696   ,\n",
       "        0.47571   ,  0.1636    , -0.44468999,  0.44690001, -0.93817002,\n",
       "        0.013101  ,  0.085964  , -0.67456001,  0.49662   , -0.037827  ,\n",
       "       -0.11038   , -0.28612   ,  0.074606  , -0.31527001, -0.093774  ,\n",
       "       -0.57068998,  0.66864997,  0.45307001, -0.34154001, -0.7166    ,\n",
       "       -0.75273001,  0.075212  ,  0.57902998, -0.1191    , -0.11379   ,\n",
       "       -0.10026   ,  0.71341002, -1.15740001, -0.74026   ,  0.40452   ,\n",
       "        0.18023001,  0.21449   ,  0.37638   ,  0.11239   , -0.53639001,\n",
       "       -0.025092  ,  0.31885999, -0.25013   , -0.63283002, -0.011843  ,\n",
       "        1.37699997,  0.86013001,  0.20476   , -0.36815   , -0.68874002,\n",
       "        0.53512001, -0.46555999,  0.27388999,  0.4118    , -0.85399997,\n",
       "       -0.046288  ,  0.11304   , -0.27326   ,  0.15636   , -0.20333999,\n",
       "        0.53586   ,  0.59784001,  0.60469002,  0.13734999,  0.42232001,\n",
       "       -0.61278999, -0.38486001,  0.35842001, -0.48464   ,  0.30728   ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Found 19997 texts.\n"
     ]
    }
   ],
   "source": [
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "texts = []  # list of text samples 所有文本的列表\n",
    "labels_index = {}  # dictionary mapping label name to numeric id 类名与序号的映射字典\n",
    "labels = []  # list of label ids 每个文本对应的类的编号\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)): # 每个类的名字\n",
    "    path = os.path.join(TEXT_DATA_DIR, name) #每个类所在文件夹的路径\n",
    "    if os.path.isdir(path): \n",
    "        label_id = len(labels_index) \n",
    "        labels_index[name] = label_id # 类名与序号的映射字典\n",
    "        for fname in sorted(os.listdir(path)): # fname 为每个类下的每个文件的名字\n",
    "            if fname.isdigit(): \n",
    "                fpath = os.path.join(path, fname) #获得文件的路径\n",
    "                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
    "                with open(fpath, **args) as f:\n",
    "                    t = f.read()\n",
    "                    i = t.find('\\n\\n')  # skip header\n",
    "                    if 0 < i:\n",
    "                        t = t[i:] # 去掉头部无用文字，获取正文\n",
    "                    texts.append(t)\n",
    "                labels.append(label_id)\n",
    "\n",
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_index['alt.atheism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_index['comp.graphics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_index) # 一共20个类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels) #一共19997篇文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11521"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)#分词器将被限制为待处理数据集中最常见的num_words个单词\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts) #将每个文本序列化，每个数字代表在词典中的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1237,\n",
       " 273,\n",
       " 1213,\n",
       " 1439,\n",
       " 1071,\n",
       " 1213,\n",
       " 1237,\n",
       " 273,\n",
       " 1439,\n",
       " 192,\n",
       " 2515,\n",
       " 348,\n",
       " 2964,\n",
       " 779,\n",
       " 332,\n",
       " 28,\n",
       " 45,\n",
       " 1628,\n",
       " 1439,\n",
       " 2516,\n",
       " 3,\n",
       " 1628,\n",
       " 2144,\n",
       " 780,\n",
       " 937,\n",
       " 29,\n",
       " 441,\n",
       " 2770,\n",
       " 8854,\n",
       " 4601,\n",
       " 7969,\n",
       " 11979,\n",
       " 5,\n",
       " 12806,\n",
       " 75,\n",
       " 1628,\n",
       " 19,\n",
       " 229,\n",
       " 29,\n",
       " 1,\n",
       " 937,\n",
       " 29,\n",
       " 441,\n",
       " 2770,\n",
       " 6,\n",
       " 1,\n",
       " 118,\n",
       " 558,\n",
       " 2,\n",
       " 90,\n",
       " 106,\n",
       " 482,\n",
       " 3979,\n",
       " 6602,\n",
       " 5375,\n",
       " 1871,\n",
       " 12260,\n",
       " 1632,\n",
       " 17687,\n",
       " 1828,\n",
       " 5101,\n",
       " 1828,\n",
       " 5101,\n",
       " 788,\n",
       " 1,\n",
       " 8854,\n",
       " 4601,\n",
       " 96,\n",
       " 4,\n",
       " 4601,\n",
       " 5455,\n",
       " 64,\n",
       " 1,\n",
       " 751,\n",
       " 563,\n",
       " 1716,\n",
       " 15,\n",
       " 71,\n",
       " 844,\n",
       " 24,\n",
       " 20,\n",
       " 1971,\n",
       " 5,\n",
       " 1,\n",
       " 389,\n",
       " 8854,\n",
       " 744,\n",
       " 1023,\n",
       " 1,\n",
       " 7762,\n",
       " 1300,\n",
       " 2912,\n",
       " 4601,\n",
       " 8,\n",
       " 73,\n",
       " 1698,\n",
       " 6,\n",
       " 1,\n",
       " 118,\n",
       " 558,\n",
       " 2,\n",
       " 1828,\n",
       " 5101,\n",
       " 16500,\n",
       " 13447,\n",
       " 73,\n",
       " 1261,\n",
       " 10982,\n",
       " 170,\n",
       " 66,\n",
       " 6,\n",
       " 1,\n",
       " 869,\n",
       " 2235,\n",
       " 2544,\n",
       " 534,\n",
       " 34,\n",
       " 79,\n",
       " 8854,\n",
       " 4601,\n",
       " 29,\n",
       " 6603,\n",
       " 3388,\n",
       " 264,\n",
       " 1505,\n",
       " 535,\n",
       " 49,\n",
       " 12,\n",
       " 343,\n",
       " 66,\n",
       " 60,\n",
       " 155,\n",
       " 2,\n",
       " 6603,\n",
       " 1043,\n",
       " 1,\n",
       " 427,\n",
       " 8,\n",
       " 73,\n",
       " 1698,\n",
       " 618,\n",
       " 4601,\n",
       " 417,\n",
       " 1628,\n",
       " 632,\n",
       " 11716,\n",
       " 4602,\n",
       " 814,\n",
       " 1628,\n",
       " 691,\n",
       " 3,\n",
       " 1,\n",
       " 467,\n",
       " 2163,\n",
       " 3,\n",
       " 2266,\n",
       " 7491,\n",
       " 5,\n",
       " 48,\n",
       " 15,\n",
       " 40,\n",
       " 135,\n",
       " 378,\n",
       " 8,\n",
       " 1,\n",
       " 467,\n",
       " 6359,\n",
       " 30,\n",
       " 101,\n",
       " 90,\n",
       " 1781,\n",
       " 5,\n",
       " 115,\n",
       " 101,\n",
       " 417,\n",
       " 1628,\n",
       " 632,\n",
       " 17061,\n",
       " 1448,\n",
       " 4317,\n",
       " 45,\n",
       " 860,\n",
       " 73,\n",
       " 1611,\n",
       " 2455,\n",
       " 3343,\n",
       " 467,\n",
       " 7491,\n",
       " 13132,\n",
       " 5814,\n",
       " 1301,\n",
       " 1781,\n",
       " 1,\n",
       " 467,\n",
       " 9477,\n",
       " 667,\n",
       " 11716,\n",
       " 323,\n",
       " 15,\n",
       " 1,\n",
       " 1074,\n",
       " 802,\n",
       " 332,\n",
       " 3,\n",
       " 1,\n",
       " 467,\n",
       " 558,\n",
       " 2,\n",
       " 417,\n",
       " 1628,\n",
       " 632,\n",
       " 90,\n",
       " 106,\n",
       " 482,\n",
       " 2030,\n",
       " 2408,\n",
       " 22,\n",
       " 13799,\n",
       " 853,\n",
       " 2030,\n",
       " 2408,\n",
       " 1871,\n",
       " 3793,\n",
       " 12524,\n",
       " 439,\n",
       " 3793,\n",
       " 13448,\n",
       " 691,\n",
       " 788,\n",
       " 691,\n",
       " 502,\n",
       " 1552,\n",
       " 11221,\n",
       " 116,\n",
       " 993,\n",
       " 558,\n",
       " 2,\n",
       " 2974,\n",
       " 996,\n",
       " 7674,\n",
       " 1184,\n",
       " 1346,\n",
       " 108,\n",
       " 828,\n",
       " 1871,\n",
       " 9478,\n",
       " 12807,\n",
       " 32,\n",
       " 7675,\n",
       " 460,\n",
       " 61,\n",
       " 110,\n",
       " 16,\n",
       " 3362,\n",
       " 22,\n",
       " 1950,\n",
       " 8,\n",
       " 691,\n",
       " 1711,\n",
       " 5622,\n",
       " 233,\n",
       " 1346,\n",
       " 1428,\n",
       " 4623,\n",
       " 1260,\n",
       " 12,\n",
       " 16501,\n",
       " 32,\n",
       " 1044,\n",
       " 7854,\n",
       " 564,\n",
       " 3955,\n",
       " 16501,\n",
       " 5,\n",
       " 1,\n",
       " 500,\n",
       " 3,\n",
       " 564,\n",
       " 27,\n",
       " 4602,\n",
       " 4,\n",
       " 9648,\n",
       " 2913,\n",
       " 10746,\n",
       " 558,\n",
       " 2,\n",
       " 7128,\n",
       " 97,\n",
       " 2456,\n",
       " 2420,\n",
       " 4623,\n",
       " 1260,\n",
       " 12,\n",
       " 16501,\n",
       " 90,\n",
       " 106,\n",
       " 482,\n",
       " 13133,\n",
       " 1346,\n",
       " 1428,\n",
       " 797,\n",
       " 2652,\n",
       " 632,\n",
       " 2366,\n",
       " 445,\n",
       " 3955,\n",
       " 681,\n",
       " 2477,\n",
       " 288,\n",
       " 1184,\n",
       " 15965,\n",
       " 853,\n",
       " 2797,\n",
       " 7308,\n",
       " 2797,\n",
       " 15438,\n",
       " 6902,\n",
       " 15438,\n",
       " 10747,\n",
       " 1538,\n",
       " 15000,\n",
       " 2366,\n",
       " 1380,\n",
       " 337,\n",
       " 5994,\n",
       " 681,\n",
       " 338,\n",
       " 13800,\n",
       " 3138,\n",
       " 1995,\n",
       " 2797,\n",
       " 728,\n",
       " 12808,\n",
       " 3558,\n",
       " 15438,\n",
       " 11717,\n",
       " 2797,\n",
       " 439,\n",
       " 15438,\n",
       " 11717,\n",
       " 15438,\n",
       " 1,\n",
       " 445,\n",
       " 3955,\n",
       " 681,\n",
       " 4602,\n",
       " 1,\n",
       " 4,\n",
       " 5254,\n",
       " 1689,\n",
       " 4712,\n",
       " 6,\n",
       " 1282,\n",
       " 103,\n",
       " 152,\n",
       " 6421,\n",
       " 9020,\n",
       " 19947,\n",
       " 19120,\n",
       " 141,\n",
       " 2230,\n",
       " 4545,\n",
       " 1574,\n",
       " 1282,\n",
       " 4602,\n",
       " 4,\n",
       " 2341,\n",
       " 9020,\n",
       " 2341,\n",
       " 6421,\n",
       " 9020,\n",
       " 103,\n",
       " 152,\n",
       " 19947,\n",
       " 19120,\n",
       " 141,\n",
       " 2230,\n",
       " 4545,\n",
       " 1574,\n",
       " 1282,\n",
       " 12,\n",
       " 1628,\n",
       " 691,\n",
       " 558,\n",
       " 2,\n",
       " 129,\n",
       " 6421,\n",
       " 19947,\n",
       " 141,\n",
       " 3857,\n",
       " 19121,\n",
       " 28,\n",
       " 1282,\n",
       " 1871,\n",
       " 691,\n",
       " 4429,\n",
       " 1058,\n",
       " 56,\n",
       " 1,\n",
       " 3542,\n",
       " 17062,\n",
       " 3316,\n",
       " 723,\n",
       " 889,\n",
       " 1,\n",
       " 4430,\n",
       " 1333,\n",
       " 9,\n",
       " 3542,\n",
       " 959,\n",
       " 36,\n",
       " 3158,\n",
       " 5,\n",
       " 1143,\n",
       " 19,\n",
       " 55,\n",
       " 13134,\n",
       " 2,\n",
       " 980,\n",
       " 22,\n",
       " 628,\n",
       " 2224,\n",
       " 2267,\n",
       " 107,\n",
       " 4624,\n",
       " 56,\n",
       " 2280,\n",
       " 2420,\n",
       " 4,\n",
       " 12,\n",
       " 40,\n",
       " 13135,\n",
       " 6,\n",
       " 14,\n",
       " 301,\n",
       " 4296,\n",
       " 8205,\n",
       " 8,\n",
       " 1,\n",
       " 60,\n",
       " 1930,\n",
       " 71,\n",
       " 1133,\n",
       " 6484,\n",
       " 29,\n",
       " 4984,\n",
       " 8323,\n",
       " 1,\n",
       " 6675,\n",
       " 3,\n",
       " 1063,\n",
       " 20,\n",
       " 5815,\n",
       " 5,\n",
       " 2785,\n",
       " 594,\n",
       " 701,\n",
       " 5,\n",
       " 2557,\n",
       " 8855,\n",
       " 301,\n",
       " 4296,\n",
       " 8205,\n",
       " 261,\n",
       " 6,\n",
       " 478,\n",
       " 1,\n",
       " 514,\n",
       " 12,\n",
       " 333,\n",
       " 18371,\n",
       " 9,\n",
       " 147,\n",
       " 1717,\n",
       " 2601,\n",
       " 22,\n",
       " 94,\n",
       " 55,\n",
       " 4124,\n",
       " 2590,\n",
       " 3881,\n",
       " 8206,\n",
       " 171,\n",
       " 3858,\n",
       " 8206,\n",
       " 171,\n",
       " 3858,\n",
       " 3858,\n",
       " 355,\n",
       " 125,\n",
       " 6307,\n",
       " 5,\n",
       " 359,\n",
       " 19122,\n",
       " 723,\n",
       " 2309,\n",
       " 5,\n",
       " 85,\n",
       " 2309,\n",
       " 19,\n",
       " 7763,\n",
       " 31,\n",
       " 387,\n",
       " 24,\n",
       " 117,\n",
       " 51,\n",
       " 355,\n",
       " 3120,\n",
       " 2701,\n",
       " 24,\n",
       " 51,\n",
       " 355,\n",
       " 44,\n",
       " 66,\n",
       " 511,\n",
       " 5,\n",
       " 441,\n",
       " 298,\n",
       " 82,\n",
       " 547,\n",
       " 536,\n",
       " 51,\n",
       " 491,\n",
       " 1858,\n",
       " 9,\n",
       " 51,\n",
       " 81,\n",
       " 2526,\n",
       " 58,\n",
       " 576,\n",
       " 3,\n",
       " 137,\n",
       " 51,\n",
       " 5922,\n",
       " 13449,\n",
       " 5870,\n",
       " 85,\n",
       " 1,\n",
       " 347,\n",
       " 19,\n",
       " 3,\n",
       " 58,\n",
       " 7855,\n",
       " 10348,\n",
       " 6676,\n",
       " 4,\n",
       " 5923,\n",
       " 5871,\n",
       " 4,\n",
       " 294,\n",
       " 3,\n",
       " 544,\n",
       " 5,\n",
       " 714,\n",
       " 2,\n",
       " 4,\n",
       " 1585,\n",
       " 2001,\n",
       " 2,\n",
       " 2409,\n",
       " 4,\n",
       " 6308,\n",
       " 29,\n",
       " 11478,\n",
       " 1,\n",
       " 67,\n",
       " 1,\n",
       " 5871,\n",
       " 4087,\n",
       " 2,\n",
       " 2310,\n",
       " 577,\n",
       " 29,\n",
       " 1,\n",
       " 6676,\n",
       " 1144,\n",
       " 8,\n",
       " 2786,\n",
       " 2,\n",
       " 12525,\n",
       " 4,\n",
       " 8856,\n",
       " 5,\n",
       " 8587,\n",
       " 8205,\n",
       " 4,\n",
       " 3,\n",
       " 571,\n",
       " 17063,\n",
       " 12,\n",
       " 149,\n",
       " 1758,\n",
       " 3,\n",
       " 4,\n",
       " 547,\n",
       " 323,\n",
       " 441,\n",
       " 1,\n",
       " 9182,\n",
       " 6677,\n",
       " 12,\n",
       " 1,\n",
       " 3749,\n",
       " 10008,\n",
       " 3,\n",
       " 972,\n",
       " 154,\n",
       " 1172,\n",
       " 8,\n",
       " 2602,\n",
       " 119,\n",
       " 85,\n",
       " 1725,\n",
       " 30,\n",
       " 4,\n",
       " 5456,\n",
       " 2738,\n",
       " 5338,\n",
       " 3,\n",
       " 2678,\n",
       " 24,\n",
       " 1370,\n",
       " 3077,\n",
       " 2478,\n",
       " 51,\n",
       " 8,\n",
       " 10983,\n",
       " 30,\n",
       " 85,\n",
       " 15439,\n",
       " 5,\n",
       " 1628,\n",
       " 916,\n",
       " 5,\n",
       " 12806,\n",
       " 75,\n",
       " 3329,\n",
       " 3158,\n",
       " 1,\n",
       " 3077,\n",
       " 4271,\n",
       " 137,\n",
       " 544,\n",
       " 30,\n",
       " 531,\n",
       " 4,\n",
       " 886,\n",
       " 1623,\n",
       " 6977,\n",
       " 21,\n",
       " 280,\n",
       " 4498,\n",
       " 29,\n",
       " 209,\n",
       " 1786,\n",
       " 140,\n",
       " 1140,\n",
       " 280,\n",
       " 8,\n",
       " 4741,\n",
       " 5,\n",
       " 200,\n",
       " 16,\n",
       " 9649,\n",
       " 30,\n",
       " 4,\n",
       " 628,\n",
       " 313,\n",
       " 1106,\n",
       " 1725,\n",
       " 8,\n",
       " 8207,\n",
       " 2,\n",
       " 408,\n",
       " 2200,\n",
       " 715,\n",
       " 3406,\n",
       " 2121,\n",
       " 19948,\n",
       " 1,\n",
       " 8324,\n",
       " 4,\n",
       " 889,\n",
       " 323,\n",
       " 15,\n",
       " 1,\n",
       " 4431,\n",
       " 9,\n",
       " 1,\n",
       " 118,\n",
       " 1166,\n",
       " 8,\n",
       " 5,\n",
       " 9479,\n",
       " 1939,\n",
       " 179,\n",
       " 1535,\n",
       " 3,\n",
       " 1,\n",
       " 1718,\n",
       " 2,\n",
       " 261,\n",
       " 11,\n",
       " 132,\n",
       " 248,\n",
       " 1,\n",
       " 378,\n",
       " 8,\n",
       " 1,\n",
       " 17688,\n",
       " 3,\n",
       " 4,\n",
       " 11718,\n",
       " 275,\n",
       " 21,\n",
       " 280,\n",
       " 4339,\n",
       " 2,\n",
       " 487,\n",
       " 223,\n",
       " 1,\n",
       " 108,\n",
       " 422,\n",
       " 6550,\n",
       " 132,\n",
       " 2,\n",
       " 197,\n",
       " 1686,\n",
       " 8,\n",
       " 5,\n",
       " 71,\n",
       " 1904,\n",
       " 3058,\n",
       " 19,\n",
       " 1413,\n",
       " 5995,\n",
       " 19,\n",
       " 14183,\n",
       " 5,\n",
       " 1,\n",
       " 784,\n",
       " 8,\n",
       " 76,\n",
       " 151,\n",
       " 12,\n",
       " 10178,\n",
       " 29,\n",
       " 1,\n",
       " 467,\n",
       " 2679,\n",
       " 19,\n",
       " 5763,\n",
       " 2345,\n",
       " 60,\n",
       " 3139,\n",
       " 845,\n",
       " 4625,\n",
       " 6,\n",
       " 1,\n",
       " 309,\n",
       " 210,\n",
       " 19,\n",
       " 220,\n",
       " 5,\n",
       " 11719,\n",
       " 1349,\n",
       " 1922,\n",
       " 8,\n",
       " 1120,\n",
       " 2,\n",
       " 79,\n",
       " 151,\n",
       " 2,\n",
       " 31,\n",
       " 126,\n",
       " 24,\n",
       " 1,\n",
       " 8324,\n",
       " 9330,\n",
       " 68,\n",
       " 5,\n",
       " 68,\n",
       " 16502,\n",
       " 21,\n",
       " 11,\n",
       " 654,\n",
       " 15,\n",
       " 814,\n",
       " 3187,\n",
       " 1,\n",
       " 467,\n",
       " 14,\n",
       " 2009,\n",
       " 8720,\n",
       " 5,\n",
       " 19123,\n",
       " 156,\n",
       " 52,\n",
       " 491,\n",
       " 83,\n",
       " 15966,\n",
       " 240,\n",
       " 11,\n",
       " 8,\n",
       " 255,\n",
       " 811,\n",
       " 655,\n",
       " 23,\n",
       " 76,\n",
       " 48,\n",
       " 9,\n",
       " 1008,\n",
       " 74,\n",
       " 35,\n",
       " 36,\n",
       " 1,\n",
       " 16503,\n",
       " 8,\n",
       " 44,\n",
       " 11,\n",
       " 959,\n",
       " 6,\n",
       " 125,\n",
       " 251,\n",
       " 1680,\n",
       " 48,\n",
       " 122,\n",
       " 203,\n",
       " 13,\n",
       " 79,\n",
       " 1,\n",
       " 40,\n",
       " 254,\n",
       " 332,\n",
       " 691,\n",
       " 314,\n",
       " 4429,\n",
       " 870,\n",
       " 415,\n",
       " 13136,\n",
       " 3,\n",
       " 582,\n",
       " 632,\n",
       " 1649,\n",
       " 536,\n",
       " 415,\n",
       " 13136,\n",
       " 253,\n",
       " 2,\n",
       " 16,\n",
       " 422,\n",
       " 22,\n",
       " 114,\n",
       " 1787,\n",
       " 14,\n",
       " 8,\n",
       " 4,\n",
       " 117,\n",
       " 500,\n",
       " 3,\n",
       " 13450,\n",
       " 17689,\n",
       " 207,\n",
       " 1839,\n",
       " 2297,\n",
       " 995,\n",
       " 1165,\n",
       " 2268,\n",
       " 549,\n",
       " 2330,\n",
       " 1213,\n",
       " 4,\n",
       " 6307,\n",
       " 3559,\n",
       " 3078,\n",
       " 219,\n",
       " 632,\n",
       " 2527,\n",
       " 780,\n",
       " 4,\n",
       " 3215,\n",
       " 5,\n",
       " 7856,\n",
       " 3559,\n",
       " 3,\n",
       " 1213,\n",
       " 1301,\n",
       " 32,\n",
       " 10179,\n",
       " 6756,\n",
       " 7970,\n",
       " 5,\n",
       " 2753,\n",
       " 6,\n",
       " 14,\n",
       " 1341,\n",
       " 534,\n",
       " 11479,\n",
       " 194,\n",
       " 12,\n",
       " 3170,\n",
       " 1213,\n",
       " 7,\n",
       " 103,\n",
       " 1,\n",
       " 314,\n",
       " 973,\n",
       " 6,\n",
       " 1,\n",
       " 970,\n",
       " 3,\n",
       " 137,\n",
       " 87,\n",
       " 5,\n",
       " 86,\n",
       " 12,\n",
       " 1840,\n",
       " 1213,\n",
       " 1,\n",
       " 973,\n",
       " 6,\n",
       " 1,\n",
       " 314,\n",
       " 970,\n",
       " 3,\n",
       " 137,\n",
       " 87,\n",
       " 838,\n",
       " 272,\n",
       " 3,\n",
       " 1,\n",
       " 134,\n",
       " 12809,\n",
       " 1403,\n",
       " 12,\n",
       " 137,\n",
       " 699,\n",
       " 1796,\n",
       " 8,\n",
       " 1476,\n",
       " 2,\n",
       " 4432,\n",
       " 135,\n",
       " 21,\n",
       " 5,\n",
       " 1506,\n",
       " 4317,\n",
       " 45,\n",
       " 14581,\n",
       " 47,\n",
       " 15001,\n",
       " 9826,\n",
       " 86,\n",
       " 229,\n",
       " 1,\n",
       " 238,\n",
       " 245,\n",
       " 972,\n",
       " 3078,\n",
       " 219,\n",
       " 632,\n",
       " 4,\n",
       " 3859,\n",
       " 12526,\n",
       " 3,\n",
       " 972,\n",
       " 6,\n",
       " 61,\n",
       " 51,\n",
       " 6604,\n",
       " 1,\n",
       " 259,\n",
       " 7764,\n",
       " 3,\n",
       " 972,\n",
       " 5,\n",
       " 5171,\n",
       " 7309,\n",
       " 9,\n",
       " 27,\n",
       " 19,\n",
       " 5,\n",
       " 22,\n",
       " 18372,\n",
       " 8857,\n",
       " 1506,\n",
       " 4317,\n",
       " 45,\n",
       " 19124,\n",
       " 78,\n",
       " 802,\n",
       " 6309,\n",
       " 204,\n",
       " 137,\n",
       " 204,\n",
       " 7129,\n",
       " 1,\n",
       " 13451,\n",
       " 6116,\n",
       " 219,\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174074 unique tokens.\n",
      "Shape of data tensor: (19997, 1000)\n",
      "Shape of label tensor: (19997, 20)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index #返回字典类型，将单词（字符串）映射为它们的排名或者索引。\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3999"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15998, 1000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 1000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "174074\n"
     ]
    }
   ],
   "source": [
    "print(MAX_NUM_WORDS)\n",
    "print(len(word_index) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 996, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 195, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 2,247,316\n",
      "Trainable params: 247,316\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train a 1D convnet with global maxpooling\n",
    "print('Training model.')\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15998 samples, validate on 3999 samples\n",
      "Epoch 1/10\n",
      "15998/15998 [==============================] - 10s - loss: 2.6226 - acc: 0.1259 - val_loss: 2.2455 - val_acc: 0.2198\n",
      "Epoch 2/10\n",
      "15998/15998 [==============================] - 8s - loss: 1.9831 - acc: 0.3085 - val_loss: 1.7260 - val_acc: 0.3831\n",
      "Epoch 3/10\n",
      "15998/15998 [==============================] - 8s - loss: 1.5362 - acc: 0.4574 - val_loss: 1.5859 - val_acc: 0.4401\n",
      "Epoch 4/10\n",
      "15998/15998 [==============================] - 8s - loss: 1.2780 - acc: 0.5623 - val_loss: 1.1375 - val_acc: 0.6109\n",
      "Epoch 5/10\n",
      "15998/15998 [==============================] - 8s - loss: 1.0876 - acc: 0.6271 - val_loss: 1.0764 - val_acc: 0.6229\n",
      "Epoch 6/10\n",
      "15998/15998 [==============================] - 8s - loss: 0.9450 - acc: 0.6711 - val_loss: 1.0140 - val_acc: 0.6532\n",
      "Epoch 7/10\n",
      "15998/15998 [==============================] - 8s - loss: 0.8203 - acc: 0.7148 - val_loss: 0.9496 - val_acc: 0.6792\n",
      "Epoch 8/10\n",
      "15998/15998 [==============================] - 8s - loss: 0.7295 - acc: 0.7477 - val_loss: 0.9722 - val_acc: 0.6772\n",
      "Epoch 9/10\n",
      "15998/15998 [==============================] - 8s - loss: 0.6392 - acc: 0.7764 - val_loss: 0.9304 - val_acc: 0.7019\n",
      "Epoch 10/10\n",
      "15998/15998 [==============================] - 8s - loss: 0.5641 - acc: 0.8070 - val_loss: 0.9059 - val_acc: 0.70920.80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87942a7b00>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
